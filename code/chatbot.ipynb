{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **1. Kết nối với google drive**"],"metadata":{"id":"LFnsMd1txWtZ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"COP44ANVwpSg","executionInfo":{"status":"ok","timestamp":1680164627285,"user_tz":-420,"elapsed":46599,"user":{"displayName":"Thư Phạm Anh","userId":"05088976233535436552"}},"outputId":"f288d6d7-310f-4858-e1d5-a0b349ade312"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/NLP 4+1/Cuối kỳ/pre-trained'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["# kết nối với gg drive\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","os.chdir('/content/drive/MyDrive/NLP 4+1/Cuối kỳ/pre-trained/')\n","os.getcwd()"]},{"cell_type":"markdown","source":["# **2. Install và import các thư viện cần thiết**"],"metadata":{"id":"_G5s0Q9xxrhd"}},{"cell_type":"code","source":["!pip install transformers --quiet\n","!pip install keras_preprocessing --quiet\n","!pip install pyvi --quiet"],"metadata":{"id":"RADlL9cc1glw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680164868069,"user_tz":-420,"elapsed":26073,"user":{"displayName":"Thư Phạm Anh","userId":"05088976233535436552"}},"outputId":"ede6bff8-43c7-46d4-d821-c37ea08eb749"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import os\n","import re\n","import time\n","import torch\n","import pickle\n","import numpy as np\n","import pandas as pd\n","\n","from pyvi import ViTokenizer\n","from keras.models import load_model\n","from keras_preprocessing.sequence import pad_sequences\n","# from transformers import GPT2LMHeadModel, BertLMHeadModel\n","\n","import nltk\n","nltk.download('punkt')\n","\n","from nltk import word_tokenize\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"h2XwxLVqxZBA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680164878424,"user_tz":-420,"elapsed":10378,"user":{"displayName":"Thư Phạm Anh","userId":"05088976233535436552"}},"outputId":"34b23818-51d7-4ff9-a540-62e12bc98c9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"markdown","source":["# **3. Set các biến cục bộ và load dữ liệu**"],"metadata":{"id":"zm3qW-uVxvCu"}},{"cell_type":"code","source":["def preprocess(text):\n","    text = text.lower()                                                 # chuyển về chữ thường\n","    text = re.sub(r'[!“”\"’#$%&\\()*+,./:;<=>?@[\\]^_`{|}~]', \"\", text)    # loại bỏ kí tự đặt biệt\n","    text = ViTokenizer.tokenize(text)                                   # word segmentation\n","    return text"],"metadata":{"id":"jwEGJ_ijxOXl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loading\n","def load_file(path):\n","    with open(path, 'rb') as handle:\n","        data = pickle.load(handle)\n","    return data"],"metadata":{"id":"ALHY4tFVyu2p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"MsWtlBl9yoc6","executionInfo":{"status":"ok","timestamp":1680164878430,"user_tz":-420,"elapsed":33,"user":{"displayName":"Thư Phạm Anh","userId":"05088976233535436552"}},"outputId":"684059ae-72cf-4a8c-95bf-6d52e6ee4382"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["# **4. Load pre-trained cho các model**"],"metadata":{"id":"mnkkuvh09Czl"}},{"cell_type":"markdown","source":["## ***4.1 Model GPT***"],"metadata":{"id":"Xu6q5a5jBkSy"}},{"cell_type":"code","source":["tokenizer_GPT = load_file('./GPT/tokenizer.pickle')\n","model_GPT = load_file('./GPT/GPT2LMHeadModel.pickle')"],"metadata":{"id":"PUVigIik1QvC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_GPT.resize_token_embeddings(len(tokenizer_GPT))\n","model_GPT = model_GPT.to(device)\n","if device == 'cpu':\n","    model_GPT.load_state_dict(torch.load('./GPT/model_GPT.pt', map_location ='cpu'))\n","else:\n","    model_GPT.load_state_dict(torch.load('./GPT/model_GPT.pt'))"],"metadata":{"id":"FBd098mF3W1L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def GPT_answer(inp, tokenizer=tokenizer_GPT, model=model_GPT):\n","    inp = '<s> '+ preprocess(inp) +\" <bot>: \"\n","    inp = tokenizer(inp, return_tensors=\"pt\")\n","    X = inp[\"input_ids\"].to(device)\n","    mask = inp[\"attention_mask\"].to(device)\n","    output = model.generate(X, attention_mask=mask, max_length=32, pad_token_id=0, eos_token_id=50256)\n","    output = tokenizer.decode(output[0])\n","    try:\n","        result = re.search(r'<bot>:(.*?)</s>', output).group(1).strip()\n","    except:\n","        result = re.search(r'<bot>:\\s*(.*)', output).group(1).strip()\n","    return result"],"metadata":{"id":"6gotB4qmyTGF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["GPT_answer(\"bạn có người yêu chưa?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"qQFJwaLI1mWo","executionInfo":{"status":"ok","timestamp":1680164932526,"user_tz":-420,"elapsed":2102,"user":{"displayName":"Thư Phạm Anh","userId":"05088976233535436552"}},"outputId":"feba9286-831d-4600-afdb-0e6c8c13fa42"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'mình chưa có người_yêu bạn nhé'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## ***4.2 Model LSTM, BiLSTM***"],"metadata":{"id":"D8B2f_WMIsR5"}},{"cell_type":"code","source":["# LSTM (100 epoch)\n","tokenizer_LSTM_100 = load_file( './LSTM (100 epoch)/tokenizer.pickle')\n","enc_model_LSTM_100 = load_model('./LSTM (100 epoch)/enc_model.h5')\n","dec_model_LSTM_100 = load_model('./LSTM (100 epoch)/dec_model.h5')\n","\n","# LSTM (200 epoch)\n","tokenizer_LSTM_200 = load_file( './LSTM (200 epoch)/tokenizer.pickle')\n","enc_model_LSTM_200 = load_model('./LSTM (200 epoch)/enc_model.h5')\n","dec_model_LSTM_200 = load_model('./LSTM (200 epoch)/dec_model.h5')\n","\n","# LSTM + Attention (100 epoch)\n","tokenizer_LSTM_Attention_100 = load_file( './LSTM + Attention (100 epoch)/tokenizer.pickle')\n","enc_model_LSTM_Attention_100 = load_model('./LSTM + Attention (100 epoch)/enc_model.h5')\n","dec_model_LSTM_Attention_100 = load_model('./LSTM + Attention (100 epoch)/dec_model.h5')\n","\n","# LSTM + Attention (200 epoch)\n","tokenizer_LSTM_Attention_200 = load_file( './LSTM + Attention (200 epoch)/tokenizer.pickle')\n","enc_model_LSTM_Attention_200 = load_model('./LSTM + Attention (200 epoch)/enc_model.h5')\n","dec_model_LSTM_Attention_200 = load_model('./LSTM + Attention (200 epoch)/dec_model.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-C4ZHONnI43X","executionInfo":{"status":"ok","timestamp":1680164970935,"user_tz":-420,"elapsed":22624,"user":{"displayName":"Thư Phạm Anh","userId":"05088976233535436552"}},"outputId":"a9dadb1c-25f2-4145-d963-33937ce49f5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]}]},{"cell_type":"code","source":["# BiLSTM (100 epoch)\n","tokenizer_BiLSTM_100 = load_file( './BiLSTM (100 epoch)/tokenizer.pickle')\n","enc_model_BiLSTM_100 = load_model('./BiLSTM (100 epoch)/enc_model.h5')\n","dec_model_BiLSTM_100 = load_model('./BiLSTM (100 epoch)/dec_model.h5')\n","\n","# BiLSTM (200 epoch)\n","tokenizer_BiLSTM_200 = load_file( './BiLSTM (200 epoch)/tokenizer.pickle')\n","enc_model_BiLSTM_200 = load_model('./BiLSTM (200 epoch)/enc_model.h5')\n","dec_model_BiLSTM_200 = load_model('./BiLSTM (200 epoch)/dec_model.h5')\n","\n","# BiLSTM + Attention (100 epoch)\n","tokenizer_BiLSTM_Attention_100 = load_file( './BiLSTM + Attention (100 epoch)/tokenizer.pickle')\n","enc_model_BiLSTM_Attention_100 = load_model('./BiLSTM + Attention (100 epoch)/enc_model.h5')\n","dec_model_BiLSTM_Attention_100 = load_model('./BiLSTM + Attention (100 epoch)/dec_model.h5')\n","\n","# BiLSTM + Attention (200 epoch)\n","tokenizer_BiLSTM_Attention_200 = load_file( './BiLSTM + Attention (200 epoch)/tokenizer.pickle')\n","enc_model_BiLSTM_Attention_200 = load_model('./BiLSTM + Attention (200 epoch)/enc_model.h5')\n","dec_model_BiLSTM_Attention_200 = load_model('./BiLSTM + Attention (200 epoch)/dec_model.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h5VgUaruoquL","executionInfo":{"status":"ok","timestamp":1680164996339,"user_tz":-420,"elapsed":24602,"user":{"displayName":"Thư Phạm Anh","userId":"05088976233535436552"}},"outputId":"06a6d035-dba7-4c84-a431-094b4aa31658"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]}]},{"cell_type":"code","source":["MAXLEN_QUESTION = 15\n","MAXLEN_ANSWER = 15\n","def str_to_tokens(sentence, tokenizer):\n","    words = preprocess(sentence)\n","    tokens_list = tokenizer.texts_to_sequences([words])\n","    return pad_sequences(tokens_list, maxlen=MAXLEN_QUESTION,padding='post')\n","    \n","def LSTM_BiLSTM_answer(question, type_model, with_epochs):\n","    if with_epochs == 100:\n","        if type_model == 'LSTM':\n","            tokenizer, enc_model, dec_model = tokenizer_LSTM_100, enc_model_LSTM_100, dec_model_LSTM_100\n","        elif type_model == 'BiLSTM':\n","            tokenizer, enc_model, dec_model = tokenizer_BiLSTM_100, enc_model_BiLSTM_100, dec_model_BiLSTM_100\n","    elif with_epochs == 200:\n","        if type_model == 'LSTM':\n","            tokenizer, enc_model, dec_model = tokenizer_LSTM_200, enc_model_LSTM_200, dec_model_LSTM_200\n","        elif type_model == 'BiLSTM':\n","            tokenizer, enc_model, dec_model = tokenizer_BiLSTM_200, enc_model_BiLSTM_200, dec_model_BiLSTM_200\n","\n","    states_values = enc_model.predict(str_to_tokens(question, tokenizer), verbose=0)\n","    empty_target_seq = np.zeros((1,1))\n","    empty_target_seq[0,0] = tokenizer.word_index['<s>']\n","    stop_condition = False\n","    generated_answer = ''\n","    while not stop_condition:\n","        dec_outputs, h, c = dec_model.predict([empty_target_seq]+states_values, verbose=0)\n","        sampled_word_index = np.argmax(dec_outputs[0,-1, :])\n","        sampled_word = None\n","        for word, index in tokenizer.word_index.items():\n","            if sampled_word_index == index:\n","                if word != '</s>':\n","                    generated_answer += f'{word} '\n","                sampled_word = word\n","\n","        if sampled_word == '</s>' or len(generated_answer.split()) > MAXLEN_ANSWER:\n","            stop_condition = True\n","        empty_target_seq = np.zeros((1,1))\n","        empty_target_seq[0,0] = sampled_word_index\n","        states_values = [h,c]\n","\n","    return generated_answer.strip()\n","\n","def LSTM_BiLSTM_Attention_answer(question, type_model, with_epochs):\n","    if with_epochs == 100:\n","        if type_model == 'LSTM':\n","            tokenizer, enc_model, dec_model = tokenizer_LSTM_Attention_100, enc_model_LSTM_Attention_100, dec_model_LSTM_Attention_100\n","        elif type_model == 'BiLSTM':\n","            tokenizer, enc_model, dec_model = tokenizer_BiLSTM_Attention_100, enc_model_BiLSTM_Attention_100, dec_model_BiLSTM_Attention_100\n","    elif with_epochs == 200:\n","        if type_model == 'LSTM':\n","            tokenizer, enc_model, dec_model = tokenizer_LSTM_Attention_200, enc_model_LSTM_Attention_200, dec_model_LSTM_Attention_200\n","        elif type_model == 'BiLSTM':\n","            tokenizer, enc_model, dec_model = tokenizer_BiLSTM_Attention_200, enc_model_BiLSTM_Attention_200, dec_model_BiLSTM_Attention_200\n","\n","    values,h,c = enc_model.predict(str_to_tokens(question, tokenizer), verbose=0)\n","    empty_target_seq = np.zeros((1,1))\n","    empty_target_seq[0,0] = tokenizer.word_index['<s>']\n","    stop_condition = False\n","    generated_answer = ''\n","\n","    while not stop_condition:\n","        dec_outputs, h_state,c_state = dec_model.predict([empty_target_seq]+[values,h,c], verbose=0)\n","        sampled_word_index = np.argmax(dec_outputs[0,-1, :])\n","        sampled_word = None\n","        for word, index in tokenizer.word_index.items():\n","            if sampled_word_index == index:\n","                if word != '</s>':\n","                    generated_answer += f'{word} '\n","                sampled_word = word\n","\n","        if sampled_word == '</s>' or len(generated_answer.split()) > MAXLEN_ANSWER:\n","            stop_condition = True\n","        empty_target_seq = np.zeros((1,1))\n","        empty_target_seq[0,0] = sampled_word_index\n","        h,c = h_state,c_state\n","\n","    return generated_answer.strip()"],"metadata":{"id":"eYU9bTn_JMgT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('LSTM (100 epochs):', LSTM_BiLSTM_answer('bạn có người yêu chưa?', type_model='LSTM', with_epochs=100))\n","print('LSTM (200 epochs):', LSTM_BiLSTM_answer('bạn có người yêu chưa?', type_model='LSTM', with_epochs=200))\n","print('LSTM + Attention (100 epochs):', LSTM_BiLSTM_Attention_answer('bạn có người yêu chưa?', type_model='LSTM', with_epochs=100))\n","print('LSTM + Attention (200 epochs):', LSTM_BiLSTM_Attention_answer('bạn có người yêu chưa?', type_model='LSTM', with_epochs=200))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FjsXahziovDx","executionInfo":{"status":"ok","timestamp":1680165029875,"user_tz":-420,"elapsed":1075,"user":{"displayName":"Thư Phạm Anh","userId":"05088976233535436552"}},"outputId":"90d496d6-4924-422c-918c-e2a8c4f938bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LSTM (100 epochs): có\n","LSTM (200 epochs): tôi có người_yêu rồi\n","LSTM + Attention (100 epochs): có\n","LSTM + Attention (200 epochs): vẫn chưa\n"]}]},{"cell_type":"code","source":["print('BiLSTM (100 epochs):', LSTM_BiLSTM_answer('bạn có người yêu chưa?', type_model='BiLSTM', with_epochs=100))\n","print('BiLSTM (200 epochs):', LSTM_BiLSTM_answer('bạn có người yêu chưa?', type_model='BiLSTM', with_epochs=200))\n","print('BiLSTM + Attention (100 epochs):', LSTM_BiLSTM_Attention_answer('bạn có người yêu chưa?', type_model='BiLSTM', with_epochs=100))\n","print('BiLSTM + Attention (200 epochs):', LSTM_BiLSTM_Attention_answer('bạn có người yêu chưa?', type_model='BiLSTM', with_epochs=200))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"COQT9zi5owxy","executionInfo":{"status":"ok","timestamp":1680165033910,"user_tz":-420,"elapsed":1888,"user":{"displayName":"Thư Phạm Anh","userId":"05088976233535436552"}},"outputId":"7cd0794f-f044-4bf8-ce6b-192cb00f67de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BiLSTM (100 epochs): có\n","BiLSTM (200 epochs): mình chưa có người_yêu\n","BiLSTM + Attention (100 epochs): mình không thích gì thế_giới lên kinh_tế\n","BiLSTM + Attention (200 epochs): mình có người_yêu rồi\n"]}]},{"cell_type":"markdown","source":["# **5. Chat với các model**"],"metadata":{"id":"JkWk7bIjEL77"}},{"cell_type":"code","source":["def chatbot_all(inp):\n","    print('USER                      :', inp)\n","    print('(LSTM 100)                :', LSTM_BiLSTM_answer(inp, type_model='LSTM', with_epochs=100)) \n","    print('(LSTM 200)                :', LSTM_BiLSTM_answer(inp, type_model='LSTM', with_epochs=200))\n","    print('(LSTM + Attention 100)    :', LSTM_BiLSTM_Attention_answer(inp, type_model='LSTM', with_epochs=100)) \n","    print('(LSTM + Attention 200)    :', LSTM_BiLSTM_Attention_answer(inp, type_model='LSTM', with_epochs=200)) \n","    print('(BiLSTM 100)              :', LSTM_BiLSTM_answer(inp, type_model='BiLSTM', with_epochs=100)) \n","    print('(BiLSTM 200)              :', LSTM_BiLSTM_answer(inp, type_model='BiLSTM', with_epochs=200))\n","    print('(BiLSTM + Attention 100)  :', LSTM_BiLSTM_Attention_answer(inp, type_model='BiLSTM', with_epochs=100)) \n","    print('(BiLSTM + Attention 200)  :', LSTM_BiLSTM_Attention_answer(inp, type_model='BiLSTM', with_epochs=200))\n","    print('(GPT)                     :', GPT_answer(inp)) \n","      \n","chatbot_all('bạn có người yêu chưa?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4BVQ00B_EK8p","executionInfo":{"status":"ok","timestamp":1680165125322,"user_tz":-420,"elapsed":3731,"user":{"displayName":"Thư Phạm Anh","userId":"05088976233535436552"}},"outputId":"244d8ed8-6e13-4209-a115-d541c41cd454"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["USER                      : bạn có người yêu chưa?\n","(LSTM 100)                : có\n","(LSTM 200)                : tôi có người_yêu rồi\n","(LSTM + Attention 100)    : có\n","(LSTM + Attention 200)    : vẫn chưa\n","(BiLSTM 100)              : có\n","(BiLSTM 200)              : mình chưa có người_yêu\n","(BiLSTM + Attention 100)  : mình không thích gì thế_giới lên kinh_tế\n","(BiLSTM + Attention 200)  : mình có người_yêu rồi\n","(GPT)                     : mình chưa có người_yêu bạn nhé\n"]}]},{"cell_type":"code","source":["def chatbot_with_model(name_model):\n","    print('bot  : Xin chào! Tôi có thể giúp gì cho bạn?')\n","    while True:\n","        inp = input('user : ')\n","        if inp == 'tạm biệt':\n","            print('bot  : Hẹn gặp lại bạn lần sau!')\n","            break\n","            \n","        if name_model == 'LSTM_100':\n","            print('bot  :', LSTM_BiLSTM_answer(inp, type_model='LSTM', with_epochs=100))\n","        elif name_model == 'LSTM_200':\n","            print('bot  :', LSTM_BiLSTM_answer(inp, type_model='LSTM', with_epochs=200))\n","        elif name_model == 'LSTM_Attention_100':\n","            print('bot  :', LSTM_BiLSTM_Attention_answer(inp, type_model='LSTM', with_epochs=100))\n","        elif name_model == 'LSTM_Attention_200':\n","            print('bot  :', LSTM_BiLSTM_Attention_answer(inp, type_model='LSTM', with_epochs=200))\n","        elif name_model == 'BiLSTM_100':\n","            print('bot  :', LSTM_BiLSTM_answer(inp, type_model='BiLSTM', with_epochs=100))\n","        elif name_model == 'BiLSTM_200':\n","            print('bot  :', LSTM_BiLSTM_answer(inp, type_model='BiLSTM', with_epochs=200))\n","        elif name_model == 'BiLSTM_Attention_100':\n","            print('bot  :', LSTM_BiLSTM_Attention_answer(inp, type_model='BiLSTM', with_epochs=100))\n","        elif name_model == 'BiLSTM_Attention_200':\n","            print('bot  :', LSTM_BiLSTM_Attention_answer(inp, type_model='BiLSTM', with_epochs=200))\n","        elif name_model == 'GPT':\n","            print('bot  :', GPT_answer(inp))\n","\n","chatbot_with_model(name_model='BiLSTM_Attention_200')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptm_Cv3S9Qrk","executionInfo":{"status":"ok","timestamp":1680165269404,"user_tz":-420,"elapsed":17437,"user":{"displayName":"Thư Phạm Anh","userId":"05088976233535436552"}},"outputId":"1ba05174-0272-4e9a-ee9c-3168622aa850"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["bot  : Xin chào! Tôi có thể giúp gì cho bạn?\n","user : bạn học ngành gì\n","bot  : học ngôn_ngữ còn bạn\n","user : bạn ở đâu\n","bot  : mình ở quận 8\n","user : tạm biệt\n","bot  : Hẹn gặp lại bạn lần sau!\n"]}]}]}